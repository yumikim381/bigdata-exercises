{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation for the moodle exercise in Spark\n",
    "\n",
    "In this jupyter notebook we are going to preprocess the dataset that we will use in this week's graded exercise.\n",
    "1. Change directory to `exercise08` \n",
    "\n",
    "2. Start docker <br>\n",
    "`docker-compose up -d`\n",
    "\n",
    "3. Getting the data:\n",
    "    1. Download the data:<br> ```wget https://f003.backblazeb2.com/file/larsyencken-eu-public/greatlanguagegame/confusion-2014-03-02.tbz2```\n",
    "    1. Extract the data:<br> ```tar -jxvf confusion-2014-03-02.tbz2```\n",
    "\n",
    "4. Change directory to `confusion-2014-03-02`\n",
    "\n",
    "5. Extract the part of the dataset that we will work with in this exercise: ```head -n 3000000 confusion-2014-03-02.json > confusion-part.json```\n",
    "\n",
    "1. Run: `docker cp confusion-2014-03-02/ jupyter:/home/jovyan/`\n",
    "\n",
    "For more information about the dataset, you can refer to https://lars.yencken.org/datasets/great-language-game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing commands\n",
    "In your newly created notebook run these commands in order to have the dataset into an RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "spark = SparkSession.builder.master('local').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "path = \"confusion-2014-03-02/confusion-part.json\"\n",
    "raw_data = sc.textFile(path)\n",
    "dataset = raw_data.map(json.loads).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that you will be able to run the queries of the moodle question of this week. The RDD that you have to perform your queries on is the ```dataset``` one. For example, the following command returns one element of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'guess': 'Norwegian',\n",
       "  'target': 'Norwegian',\n",
       "  'country': 'AU',\n",
       "  'choices': ['Maori', 'Mandarin', 'Norwegian', 'Tongan'],\n",
       "  'sample': '48f9c924e0d98c959d8a6f1862b3ce9a',\n",
       "  'date': '2013-08-19'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest day: 2013-09-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87672"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example query 1: count the number of games played on the latest day\n",
    "latest_day = dataset \\\n",
    "    .map(lambda o: (o['date'], 0)) \\\n",
    "    .sortByKey(False) \\\n",
    "    .take(1)[0][0]\n",
    "print(\"Latest day:\", latest_day)\n",
    "dataset \\\n",
    "    .filter(lambda o: o['date'] == latest_day) \\\n",
    "    .count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
